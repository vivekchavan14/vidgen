/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as Speechify from "../../../../../../index";
/**
 * @example
 *     {
 *         input: "input",
 *         voiceId: "voice_id"
 *     }
 */
export interface GetSpeechRequest {
    /** The format for the output audio. Note, that the current default is "wav", but there's no guarantee it will not change in the future. We recommend always passing the specific param you expect. */
    audioFormat?: Speechify.tts.GetSpeechRequestAudioFormat;
    /**
     * Plain text or SSML to be synthesized to speech.
     * Refer to https://docs.sws.speechify.com/docs/api-limits for the input size limits.
     * Emotion, Pitch and Speed Rate are configured in the ssml input, please refer to the ssml documentation for more information: https://docs.sws.speechify.com/docs/ssml#prosody
     */
    input: string;
    /**
     * Language of the input. Follow the format of an ISO 639-1 language code and an ISO 3166-1 region code, separated by a hyphen, e.g. en-US.
     * Please refer to the list of the supported languages and recommendations regarding this parameter: https://docs.sws.speechify.com/docs/language-support.
     */
    language?: string;
    /** Model used for audio synthesis. `simba-base` and `simba-turbo` are deprecated. Use `simba-english` or `simba-multilingual` instead. */
    model?: Speechify.tts.GetSpeechRequestModel;
    options?: Speechify.tts.GetSpeechOptionsRequest;
    /** Id of the voice to be used for synthesizing speech. Refer to /v1/voices endpoint for available voices */
    voiceId: string;
}
